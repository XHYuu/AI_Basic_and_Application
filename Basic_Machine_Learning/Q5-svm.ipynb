{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIN7102 Applied Datamining and Text Analytics: Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Gf1badl3V1R"
   },
   "source": [
    "## Question 5: Support Vector Machine\n",
    "\n",
    "Complete and hand in this completed worksheet with your assignment submission. \n",
    "\n",
    "In this exercise you will:\n",
    "    \n",
    "- Understand the logic of the following code to use SVM for image classification.\n",
    "- Implement a linear SVM by calling functions from scikit-learn module. \n",
    "- Tune parameters of SVM. Analyze the tuned results.\n",
    "\n",
    "TEST ACC BASELINE for default SVM + PCA (128 Components) model --> 23%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU07Yq3U3V1X"
   },
   "source": [
    "#### 1. Prepare CIFAR10 dataset\n",
    "Prepare CIFAR-10 images here for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRT9brgw3V1X",
    "outputId": "630a303f-9b73-45a5-c3b8-55336291c5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training set:\n",
      "  data shape: torch.Size([50000, 32, 32, 3])\n",
      "  labels shape:  torch.Size([50000])\n",
      "Test set:\n",
      "  data shape:  torch.Size([10000, 32, 32, 3])\n",
      "  labels shape torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "cifar_trainset = datasets.CIFAR10(root='./dataset', train=True, download=True, transform=None)\n",
    "cifar_testset = datasets.CIFAR10(root='./dataset', train=False, download=True, transform=None)\n",
    "\n",
    "X_train = torch.tensor(cifar_trainset.data) / 255\n",
    "X_test = torch.tensor(cifar_testset.data) / 255\n",
    "y_train = torch.tensor(cifar_trainset.targets)\n",
    "y_test = torch.tensor(cifar_testset.targets)\n",
    "\n",
    "print('Training set:', )\n",
    "print('  data shape:', X_train.shape)\n",
    "print('  labels shape: ', y_train.shape)\n",
    "print('Test set:')\n",
    "print('  data shape: ', X_test.shape)\n",
    "print('  labels shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHb69hMm3V1Z"
   },
   "source": [
    "#### 2. Extract feature vectors\n",
    "We utilized PCA (128 components) to extract the features vectors. Please understand the logic of following code. And feel free to propose another method to improve your model, including making use of any feature selection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 128)\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################################\n",
    "# TODO:                                                                                                         #\n",
    "# Feature extraction method.                                                                                    #\n",
    "# Currently we are using PCA method to extract the features, but you can also change it to improve your model   #\n",
    "#################################################################################################################\n",
    "'''\n",
    "Reference on other feature extractors: \n",
    "1. https://medium.com/the-owl/extracting-features-from-an-intermediate-layer-of-a-pretrained-model-in-pytorch-c00589bda32b \n",
    "2. https://learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/ \n",
    "3. https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html \n",
    "'''\n",
    "# ***** START OF YOUR CODE *****\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=128)\n",
    "num_train = X_train.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "\n",
    "X_train_feat = pca.fit_transform(X_train.reshape(num_train, -1))\n",
    "X_test_feat = pca.transform(X_test.reshape(num_test, -1))\n",
    "# ***** END OF YOUR CODE *****\n",
    "\n",
    "print(X_train_feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Implement a Linear Support Vector Machine(SVM)\n",
    "Check the documentation at https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm to see how to use these functions to train and test a Support Vector Machine(SVM). Then, implement a your SVM and in the following *TODO* block. Before implementing the function, it is recommended to read the function description and NOTE inside the function. Moreover, you can only write your code in the predefined place. \n",
    "\n",
    "- You may try any kind of data preprocessing to improve your testing results\n",
    "- You may tune any parameters like kernels and penality functions, etc to improve your testing results.\n",
    "- You can also use other feature extractor other than PCA, such as LDA, resnet18, 50, transformer etc.   \n",
    "- Do not change the dataset\n",
    "- Do not use any GPU acceleration method in your implementation. We are going to evaluate your model solely using CPU. Thus, if your model training takes up more than >1 hour, we will disqualify your model from the competiton but you will still get some points.\n",
    "- Then, you need to write down what methods/ parameters you have tried and the detailed analysis of results. If you use some extra libraries in your implementation, please let us know in your analysis so that we can also reproduce your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2vd7yfY3V1a",
    "outputId": "471db747-76f8-4c80-9152-ca84630f91dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.50      0.48      1000\n",
      "           1       0.46      0.49      0.48      1000\n",
      "           2       0.31      0.30      0.30      1000\n",
      "           3       0.32      0.32      0.32      1000\n",
      "           4       0.36      0.28      0.31      1000\n",
      "           5       0.34      0.32      0.33      1000\n",
      "           6       0.42      0.50      0.46      1000\n",
      "           7       0.47      0.43      0.45      1000\n",
      "           8       0.51      0.53      0.52      1000\n",
      "           9       0.46      0.48      0.47      1000\n",
      "\n",
      "    accuracy                           0.41     10000\n",
      "   macro avg       0.41      0.41      0.41     10000\n",
      "weighted avg       0.41      0.41      0.41     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#################################################################################################################\n",
    "# Step 1 TODO:                                                                                                  #\n",
    "# Training a linear SVM using training set.                                                                     #\n",
    "# You need to write code that trains a SVM. Please refer to the document of sklearn.svm.                        #\n",
    "#                                                                                                               #\n",
    "# Currently the ACC test result for default SVM + PCA (as feature extractor) is ~23%, Try to improve it!        #\n",
    "# With your own implementation                                                                                  #\n",
    "#                                                                                                               #\n",
    "# You may tune SVM parameters such as kernels and penality functions to improve your testing results.           #\n",
    "# You can also use other feature extractor other than PCA, such as LDA, HOG, or Deep learning pretrained models such as ResNets, Transformer etc.      #\n",
    "# Then, you need to write down what methods / parameters you have tried and the detailed analysis of results.   #\n",
    "# Note that you can either write your detailed analysis in the next block or in your answer sheet               #\n",
    "#################################################################################################################\n",
    "# *****START OF YOUR CODE *****\n",
    "\n",
    "# Create a svm instance and Train the svm instance svc with the training set samples 'X_train_feat' and labels 'y_train' as input\n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(X_train_feat, y_train)\n",
    "# *****END OF YOUR CODE *****\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "# Step 2 TODO:                                                                                         #\n",
    "# Using the trained SVM to predict the classification results of validation set.                       #\n",
    "# You need to write code that test the SVM you implemented above.                                      #\n",
    "# Again you may refer to the document to see if any functions are already defined for prediction.      #\n",
    "########################################################################################################\n",
    "# ***** START OF YOUR CODE *****\n",
    "\n",
    "# Test our trained svm instance svc with the test set samples 'X_test_feat'\n",
    "y2_pred = svc.predict(X_test_feat)\n",
    "# ***** END OF YOUR CODE *****\n",
    "\n",
    "# Print the predicted outputs and accuracies.\n",
    "# We use precision, recall and f-measure to measure the accuracy of image classification. \n",
    "# To understand the meaning of these metrics, you can refer to \n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html.\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better Feature Extraction\n",
    "In order to get better testing result, I will try to use pretrain resnet34 as the main feature extraction method to obtain the feature. And then I will use the SVM to complete the classify task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Use pretrain resnet 34 to extract image feature\n",
    "# resnet 18: models.ResNet18_Weights.DEFAULT\n",
    "# resnet 34: models.ResNet34_Weights.DEFAULT\n",
    "# resnet 50: models.ResNet50_Weights.DEFAULT\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "model.fc = nn.Identity()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to use transform to adapt resnet 34 (with 224x224 input image size), reload the dataset but not change any other things**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cifar_trainset = datasets.CIFAR10(root='./dataset', train=True, download=False, transform=transform)\n",
    "cifar_testset = datasets.CIFAR10(root='./dataset', train=False, download=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(cifar_trainset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(cifar_testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train dataset feature extract: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [17:35<00:00,  1.35s/it]\n",
      "test dataset feature extract: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [03:23<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 512)\n",
      "(50000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_features(model, loader, tip):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(loader,f\"{tip} dataset feature extract: \"):\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs)\n",
    "            labels.append(targets)\n",
    "    features = torch.cat(features, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    return features.numpy(), labels.numpy()\n",
    "\n",
    "X_train_feat, y_train = extract_features(model, train_loader,\"train\")\n",
    "X_test_feat, y_test = extract_features(model, test_loader,\"test\")\n",
    "featrue_extraction_time = time.time()\n",
    "\n",
    "print(X_train_feat.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      1000\n",
      "           1       0.93      0.94      0.94      1000\n",
      "           2       0.82      0.84      0.83      1000\n",
      "           3       0.77      0.81      0.79      1000\n",
      "           4       0.84      0.85      0.84      1000\n",
      "           5       0.86      0.85      0.86      1000\n",
      "           6       0.92      0.88      0.90      1000\n",
      "           7       0.92      0.89      0.90      1000\n",
      "           8       0.94      0.93      0.94      1000\n",
      "           9       0.94      0.91      0.93      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "Feature extract time consumption 1259.9525394439697\n",
      "SVM time consumption: 169.76516246795654\n",
      "Total time consumption: 1429.7177019119263\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################################\n",
    "# Step 1 TODO:                                                                                                  #\n",
    "# Training a linear SVM using training set.                                                                     #\n",
    "#################################################################################################################\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_feat, y_train)\n",
    "\n",
    "########################################################################################################\n",
    "# Step 2 TODO:                                                                                         #\n",
    "# Using the trained SVM to predict the classification results of validation set.                       #\n",
    "# Test the SVM you implemented above.                                                                  #\n",
    "########################################################################################################\n",
    "from sklearn.metrics import classification_report\n",
    "y2_pred = svm.predict(X_test_feat)\n",
    "print(classification_report(y_test, y2_pred))\n",
    "\n",
    "print(\"Feature extract time consumption\",featrue_extraction_time - start_time)\n",
    "print(\"SVM time consumption:\",time.time() - featrue_extraction_time)\n",
    "print(\"Total time consumption:\",time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:\n",
    "###############################################################################\n",
    "\n",
    "TODO: what methods/ parameters you have tried and the detailed analysis of results.\n",
    "You can give your analysis either in the notebook or in a pdf\n",
    "\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the PCA+SVM approach, it can project complex high-dimensional data into a low-dimensional space, thereby achieving a certain degree of class separation. However, since PCA reduces dimensionality by identifying the principal directions of data distribution while paying less attention to intra-class compactness and inter-class separability, the differences between different categories become less distinct after projection. This makes it difficult for the SVM to find a decision boundary that can correctly classify most of the samples during the training process. As a result, this not only increases the training time for the SVM but also lowers the final accuracy. To address this issue, I further enhanced the process by extracting information from different channels and positions of the images, while maximizing the feature distances between different categories. For this purpose, I chose to use the ResNet series for feature extraction.\n",
    "\n",
    "- ResNet introduces skip connections combined with convolutional layers, enabling the network to transform input image data into high-quality flat vectors before the final fully connected (fc) layer. At the same time, it ensures that these vectors maximize the inter-class distances in the feature space. Considering that the final testing process needs to be completed in a CPU environment within a one-hour time limit, using a small pre-trained model is essential. \n",
    "\n",
    "- During the experiment, I tested three different ResNet models: ResNet18, ResNet34 and ResNet50\n",
    "    - ResNet18: Due to its smaller size, ResNet18 was insufficient in extracting features from the input images, leading to slightly lower classification performance when fed into the SVM compared to ResNet34.\n",
    "    - ResNet34: ResNet34, with its stronger feature extraction capabilities, performed better. I removed the model's fc layer and directly fed the extracted feature vectors into the SVM for classification. To ensure proper feature extraction, I resized the input images to 224×224.\n",
    "    - ResNet50: Compared to ResNet34, ResNet50 has a more complex network structure and a larger number of parameters, theoretically enabling it to achieve more powerful image feature extraction capabilities. However, the image content in CIFAR-10 is relatively simple. On one hand, it does not require an overly complex network for feature extraction, and on the other hand, using ResNet50 for inference on a CPU takes too much time. Therefore, after testing, I decided to abandon ResNet50. \n",
    "\n",
    "- It is worth noting that, to ensure the ResNet model extracts features correctly, I resized the input images to 224×224. Finally, after approximately one hour of runtime, I achieved an 88% classification accuracy on the CIFAR-10 dataset, which meets the expected results.\n",
    "\n",
    "**Data Analysis**  \n",
    "- The experimental results show that the model based on ResNet34 feature extraction and SVM classifier achieves an overall accuracy of 88% on the CIFAR-10 dataset, and the performance is relatively stable. For example, the f1-score of categories 1, 8 and 9 reached 0.94, 0.94 and 0.93 respectively, indicating that the feature extraction of these categories was clear and the classification was accurate.  \n",
    "\n",
    "- However, for category 3, its precision is only 0.77, the lowest of all categories, which means that this kind of category may have some similarity with the other categories, leading to confusion in the classifier. Such issues could potentially be resolved by using larger models, such as ResNet50 or ResNet101, which are capable of extracting more comprehensive features and improving classification performance. However, due to limitations in hardware and time, the final classification accuracy is somewhat affected. \n",
    "\n",
    "- In addition, the running time in CPU environment is: \n",
    "    - Feature extraction: 1260 seconds (21 min)\n",
    "    - SVM process: 170 seconds (2.8 min)\n",
    "    - Total process: 1430 seconds (24 min)\n",
    "\n",
    "- Overall, by combining deep learning and traditional machine learning methods, the model balances the quality of feature extraction and the computational cost, achieving a good classification effect, but there is still room for improvement in the ability to distinguish individual category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "svm_v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1be1fd0ccaf796a3cbf7fb158f0073fdb75de9bf1651a783bd90ea5a72bbbc48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
