{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcJK3kXl--c3"
   },
   "source": [
    "# ARIN7102 Applied Datamining and Text Analytics: Assignment 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qc83ETI1a3o9"
   },
   "source": [
    "## Question 4: K-Nearest Neighbors (kNN)\n",
    "\n",
    "In this section you will implement a K-Nearest Neighbors (kNN) classifier on the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Recall that the K-Nearest Neighbor classifier is a non-parametric, supervised learning classifier, which use proxomity to make classifications or predictions about the grouping of an individual data point. A class label is assigned on the basis of a majority vote i.e., the label that is most frequently represented around a given data point is used.\n",
    "\n",
    "After implementing the K-Nearest Neighbor classifier, you will use *cross-validation* to find the best value of K.\n",
    "\n",
    "The goals of this section are to go through a simple example of the data-driven image classification pipeline, and also to practice writing efficient, vectorized code in [PyTorch](https://pytorch.org/) as most likely you will use this framework for your final project. All the best!\n",
    "\n",
    "In this section there are 6 functions / classes that you are required to fill in i.e.:\n",
    "\n",
    "- [  ] [Task] compute_distances_two_loops (3 points)\n",
    "- [  ] [Task] compute_distances_one_loop (3 points)\n",
    "- [  ] [Task] compute_distances_no_loops (3 points)\n",
    "- [  ] [Task] predict_labels (3 points)\n",
    "- [  ] [Task] KnnClassifier (6 points)\n",
    "- [  ] [Task] knn_cross_validate (6 points)\n",
    "\n",
    "* In case, if you find it hard to keep track your progress, you can also use the checkbox to track which function you have completed ([  ] / [ x ]).\n",
    "\n",
    "* You are not allowed to import other extra libraries in this section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWSgBT8Wf3tW"
   },
   "source": [
    "#### 1. Data preprocessing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tf64a0TS8zh7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GSd6jQb4epkC"
   },
   "source": [
    "#### 2. Load the CIFAR-10 dataset\n",
    "from Torchvision library, function `datasets.CIFAR10` returns the entire CIFAR-10 dataset:\n",
    "\n",
    "- `x_train` contains all training images (real numbers in the range $[0, 255]$)\n",
    "- `y_train` contains all training labels (integers in the range $[0, 9]$)\n",
    "- `x_test` contains all test images\n",
    "- `y_test` contains all test labels\n",
    "\n",
    "This function automatically downloads the CIFAR-10 dataset the first time you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "y2JiLb-R9bFb",
    "outputId": "b3ac93f5-5e8d-4152-aa04-28a482a4dcc4"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "cifar_trainset = datasets.CIFAR10(root='./dataset', train=True, download=True, transform=None)\n",
    "cifar_testset = datasets.CIFAR10(root='./dataset', train=False, download=True, transform=None)\n",
    "\n",
    "x_train_ori = torch.tensor(cifar_trainset.data) / 255\n",
    "x_test_ori = torch.tensor(cifar_testset.data) / 255\n",
    "y_train_ori = torch.tensor(cifar_trainset.targets)\n",
    "y_test_ori = torch.tensor(cifar_testset.targets)\n",
    "\n",
    "print('Training set:', )\n",
    "print('  data shape:', x_train_ori.shape)\n",
    "print('  labels shape: ', y_train_ori.shape)\n",
    "print('Test set:')\n",
    "print('  data shape: ', x_test_ori.shape)\n",
    "print('  labels shape', y_test_ori.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKKdLGIIffYx"
   },
   "source": [
    "#### 3. Visualize the dataset\n",
    "To give you a sense of the nature of the images in CIFAR-10, this cell visualizes some random examples from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "UMNVrzrd-d_y",
    "outputId": "1bd00712-3a50-4e4d-fb39-a9353c25c56e"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "samples_per_class = 12\n",
    "samples = []\n",
    "for y, cls in enumerate(classes):\n",
    "    plt.text(-4, 34 * y + 18, cls, ha='right')\n",
    "    idxs, = np.where(y_train_ori == y)\n",
    "    for i in range(samples_per_class):\n",
    "        idx = idxs[random.randrange(idxs.shape[0])].item()\n",
    "        x_train_idx = torch.Tensor(x_train_ori[idx])\n",
    "        x_train_idx = x_train_idx.swapaxes(0,2)\n",
    "        x_train_idx = x_train_idx.swapaxes(1,2)\n",
    "        samples.append(x_train_idx)\n",
    "\n",
    "img = make_grid(samples, nrow=samples_per_class)\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nLyYUhBgDKp"
   },
   "source": [
    "#### 4.  Subsample the dataset\n",
    "When implementing machine learning algorithms, it's usually a good idea to use a small sample of the full dataset. This way your code will run much faster, allowing for more interactive and efficient development. Once you are satisfied that you have correctly implemented the algorithm, you can then rerun with the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtBIn0xjhPMd"
   },
   "source": [
    "We will subsample the data to use only 500 training examples and 250 test examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_dataset(x_train, y_train, x_test, y_test, num_train=None, num_test=None):\n",
    "\n",
    "    if num_train != None:\n",
    "        x_train = x_train[:num_train]\n",
    "        y_train = y_train[:num_train]\n",
    "        \n",
    "    if num_test != None:\n",
    "        x_test = x_test[:num_test]\n",
    "        y_test = y_test[:num_test]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "FFmXwZbnG9ki",
    "outputId": "dc47bcd0-d46b-41d5-bc75-052ff7043d39"
   },
   "outputs": [],
   "source": [
    "num_train = 500\n",
    "num_test = 250\n",
    "\n",
    "x_train, y_train, x_test, y_test = subsample_dataset(x_train_ori, y_train_ori, x_test_ori, y_test_ori, num_train, num_test)\n",
    "\n",
    "print('Training set:', )\n",
    "print('  data shape:', x_train.shape)\n",
    "print('  labels shape: ', y_train.shape)\n",
    "print('Test set:')\n",
    "print('  data shape: ', x_test.shape)\n",
    "print('  labels shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-M0pmnWwgFu5"
   },
   "source": [
    "#### 5. K-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOZTkdiSmUFc"
   },
   "source": [
    "#### [Task] Compute distances: Naive implementation\n",
    "Now that we have examined and prepared our data, it is time to implement the kNN classifier. We can break the process down into two steps:\n",
    "\n",
    "1. By using a distance metric such as Euclidan distance, calculate the distance between the query point (test data) and the other data points (training data).\n",
    "2. Given these distances calculated from the first step, for each test example, find its k nearest neigbours and find the predicted label by having a vote mechanism.\n",
    "\n",
    "Lets begin with computing the distance matrix between all training and test examples. First we will implement a naive version of the distance computation, using explicit loops over the training and test sets. Implement the function `compute_distances_two_loops`! Before implementing the function, it is recommended to read the function description and NOTE inside the function. Moreover, you can only write your code in the predefined place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_two_loops(x_train, x_test):\n",
    "    \"\"\"\n",
    "    Computes the squared Euclidean distance between each element of training\n",
    "    set and each element of test set. Images should be flattened and treated\n",
    "    as vectors.\n",
    "\n",
    "    This implementation uses a naive set of nested loops over the training and\n",
    "    test data.\n",
    "\n",
    "    The input data may have any number of dimensions -- for example this\n",
    "    function should be able to compute nearest neighbor between vectors, in\n",
    "    which case the inputs will have shape (num_{train, test}, D); it should\n",
    "    also be able to compute nearest neighbors between images, where the inputs\n",
    "    will have shape (num_{train, test}, C, H, W). More generally, the inputs\n",
    "    will have shape (num_{train, test}, D1, D2, ..., Dn); you should flatten\n",
    "    each element of shape (D1, D2, ..., Dn) into a vector of shape\n",
    "    (D1 * D2 * ... * Dn) before computing distances.\n",
    "\n",
    "    The input tensors should not be modified.\n",
    "\n",
    "    NOTE: Your implementation may not use `torch.norm`, `torch.dist`,\n",
    "    `torch.cdist`, or their instance method variants (`x.norm`, `x.dist`,\n",
    "    `x.cdist`, etc.). You may not use any functions from `torch.nn` or\n",
    "    `torch.nn.functional` modules.\n",
    "\n",
    "    Args:\n",
    "        x_train: Tensor of shape (num_train, D1, D2, ...)\n",
    "        x_test: Tensor of shape (num_test, D1, D2, ...)\n",
    "\n",
    "    Returns:\n",
    "        dists: Tensor of shape (num_train, num_test) where dists[i, j]\n",
    "            is the squared Euclidean distance between the i-th training point\n",
    "            and the j-th test point. It should have the same dtype as x_train.\n",
    "    \"\"\"\n",
    "    # Initialize dists to be a tensor of shape (num_train, num_test) with the\n",
    "    # same datatype and device as x_train\n",
    "    num_train = x_train.shape[0]\n",
    "    num_test = x_test.shape[0]\n",
    "    dists = x_train.new_zeros(num_train, num_test)\n",
    "    ##########################################################################\n",
    "    # TODO: Implement this function using a pair of nested loops over the    #\n",
    "    # training data and the test data.                                       #\n",
    "    #                                                                        #\n",
    "    # You may not use torch.norm (or its instance method variant), nor any   #\n",
    "    # functions from torch.nn or torch.nn.functional.                        #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "\n",
    "    pass\n",
    "\n",
    "    ##########################################################################\n",
    "    #                           END OF YOUR CODE                             #\n",
    "    ##########################################################################\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oHq2bs_MnqVM",
    "outputId": "29d3c420-e982-4a1b-f9c8-61dfe4bbe7b9"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "dists = compute_distances_two_loops(x_train, x_test)\n",
    "print('dists has shape: ', dists.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGdFIqBEpPcQ"
   },
   "source": [
    "As a visual debugging step, we can visualize the distance matrix, where each row is a test example and each column is a training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "dshO3kmOKk0T",
    "outputId": "4ef94d74-8700-4dd8-f9f4-936fcf0e5125"
   },
   "outputs": [],
   "source": [
    "plt.imshow(dists.numpy(), cmap='gray', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xlabel('test')\n",
    "plt.ylabel('train')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHkuvdr_1HqC"
   },
   "source": [
    "#### [Task] Compute distances: Vectorization\n",
    "Our implementation of the distance computation above is fairly inefficient since it uses nested Python loops over the training and test sets.\n",
    "\n",
    "When implementing algorithms in PyTorch, it's best to avoid loops in Python if possible. Instead it is preferable to implement your computation so that all loops happen inside PyTorch functions. This will usually be much faster than writing your own loops in Python, since PyTorch functions can be internally optimized to iterate efficiently, possibly using multiple threads. This is especially important when using a GPU to accelerate your code.\n",
    "\n",
    "The process of eliminating explict loops from your code is called **vectorization**. Sometimes it is straighforward to vectorize code originally written with loops; other times vectorizing requires thinking about the problem in a new way. We will use vectorization to improve the speed of our distance computation function.\n",
    "\n",
    "As a first step toward vectorizing our distance computation, you will implement a version that uses only a single Python loop over the training data. Complete the implementation of the function `compute_distances_one_loop`! Before implementing the function, it is recommended to read the function description and NOTE inside the function. Moreover, you can only write your code in the predefined place. \n",
    "\n",
    "We can check the correctness of our one-loop implementation by comparing it with our two-loop implementation on some randomly generated data.\n",
    "\n",
    "Note that we do the comparison with 64-bit floating points for increased numeric precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_one_loop(x_train, x_test):\n",
    "    \"\"\"\n",
    "    Computes the squared Euclidean distance between each element of training\n",
    "    set and each element of test set. Images should be flattened and treated\n",
    "    as vectors.\n",
    "\n",
    "    This implementation uses only a single loop over the training data.\n",
    "\n",
    "    Similar to `compute_distances_two_loops`, this should be able to handle\n",
    "    inputs with any number of dimensions. The inputs should not be modified.\n",
    "\n",
    "    NOTE: Your implementation may not use `torch.norm`, `torch.dist`,\n",
    "    `torch.cdist`, or their instance method variants (`x.norm`, `x.dist`,\n",
    "    `x.cdist`, etc.). You may not use any functions from `torch.nn` or\n",
    "    `torch.nn.functional` modules.\n",
    "\n",
    "    Args:\n",
    "        x_train: Tensor of shape (num_train, D1, D2, ...)\n",
    "        x_test: Tensor of shape (num_test, D1, D2, ...)\n",
    "\n",
    "    Returns:\n",
    "        dists: Tensor of shape (num_train, num_test) where dists[i, j]\n",
    "            is the squared Euclidean distance between the i-th training point\n",
    "            and the j-th test point. It should have the same dtype as x_train.\n",
    "    \"\"\"\n",
    "    # Initialize dists to be a tensor of shape (num_train, num_test) with the\n",
    "    # same datatype and device as x_train\n",
    "    num_train = x_train.shape[0]\n",
    "    num_test = x_test.shape[0]\n",
    "    dists = x_train.new_zeros(num_train, num_test)\n",
    "    ##########################################################################\n",
    "    # TODO: Implement this function using only a single loop over x_train.   #\n",
    "    #                                                                        #\n",
    "    # You may not use torch.norm (or its instance method variant), nor any   #\n",
    "    # functions from torch.nn or torch.nn.functional.                        #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    pass\n",
    "    ##########################################################################\n",
    "    #                           END OF YOUR CODE                             #\n",
    "    ##########################################################################\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ujU8bWch4EmK",
    "outputId": "d322edba-53d8-47a5-cd90-069ba57e0b12"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x_train_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
    "x_test_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
    "\n",
    "dists_one = compute_distances_one_loop(x_train_rand, x_test_rand)\n",
    "dists_two = compute_distances_two_loops(x_train_rand, x_test_rand)\n",
    "difference = (dists_one - dists_two).pow(2).sum().sqrt().item()\n",
    "print('Difference: ', difference)\n",
    "if difference < 1e-4:\n",
    "    print('Good! The distance matrices match')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqtIsY6x_kb9"
   },
   "source": [
    "You will now implement a fully vectorized version of the distance computation function\n",
    "that does not use any Python loops. Implement the function `compute_distances_no_loops`. Before implementing the function, it is recommended to read the function description and NOTE inside the function. Moreover, you can only write your code in the predefined place.\n",
    "\n",
    "As before, we can check the correctness of our implementation by comparing the fully vectorized version against the original naive version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_no_loops(x_train: torch.Tensor, x_test: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Computes the squared Euclidean distance between each element of training\n",
    "    set and each element of test set. Images should be flattened and treated\n",
    "    as vectors.\n",
    "\n",
    "    This implementation should not use any Python loops. For memory-efficiency,\n",
    "    it also should not create any large intermediate tensors; in particular you\n",
    "    should not create any intermediate tensors with O(num_train * num_test)\n",
    "    elements.\n",
    "\n",
    "    Similar to `compute_distances_two_loops`, this should be able to handle\n",
    "    inputs with any number of dimensions. The inputs should not be modified.\n",
    "\n",
    "    NOTE: Your implementation may not use `torch.norm`, `torch.dist`,\n",
    "    `torch.cdist`, or their instance method variants (`x.norm`, `x.dist`,\n",
    "    `x.cdist`, etc.). You may not use any functions from `torch.nn` or\n",
    "    `torch.nn.functional` modules.\n",
    "\n",
    "    Args:\n",
    "        x_train: Tensor of shape (num_train, C, H, W)\n",
    "        x_test: Tensor of shape (num_test, C, H, W)\n",
    "\n",
    "    Returns:\n",
    "        dists: Tensor of shape (num_train, num_test) where dists[i, j] is\n",
    "            the squared Euclidean distance between the i-th training point and\n",
    "            the j-th test point.\n",
    "    \"\"\"\n",
    "    # Initialize dists to be a tensor of shape (num_train, num_test) with the\n",
    "    # same datatype and device as x_train\n",
    "    num_train = x_train.shape[0]\n",
    "    num_test = x_test.shape[0]\n",
    "    dists = x_train.new_zeros(num_train, num_test)\n",
    "    ##########################################################################\n",
    "    # TODO: Implement this function without using any explicit loops and     #\n",
    "    # without creating any intermediate tensors with O(num_train * num_test) #\n",
    "    # elements.                                                              #\n",
    "    #                                                                        #\n",
    "    # You may not use torch.norm (or its instance method variant), nor any   #\n",
    "    # functions from torch.nn or torch.nn.functional.                        #\n",
    "    #                                                                        #\n",
    "    # HINT: Try to formulate the Euclidean distance using two broadcast sums #\n",
    "    # and a matrix multiply.                                                 # \n",
    "    ##########################################################################   \n",
    "    '''\n",
    "    Reference:\n",
    "    https://stackoverflow.com/questions/27948363/numpy-broadcast-to-perform-euclidean-distance-vectorized                                       #\n",
    "    '''\n",
    "    # Replace \"pass\" statement with your code\n",
    "    \n",
    "    pass\n",
    "\n",
    "    ##########################################################################\n",
    "    #                           END OF YOUR CODE                             #\n",
    "    ##########################################################################\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1RY8QBeS9WYK",
    "outputId": "b8ed1d8e-cd2f-4a84-864a-08dbd51c1698"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x_train_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
    "x_test_rand = torch.randn(100, 3, 16, 16, dtype=torch.float64)\n",
    "\n",
    "dists_two = compute_distances_two_loops(x_train_rand, x_test_rand)\n",
    "dists_none = compute_distances_no_loops(x_train_rand, x_test_rand)\n",
    "difference = (dists_two - dists_none).pow(2).sum().sqrt().item()\n",
    "print('Difference: ', difference)\n",
    "if difference < 1e-4:\n",
    "  print('Good! The distance matrices match')\n",
    "else:\n",
    "  print('The distance matrices are different, please check your implementation again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JPMM0-BBGmt"
   },
   "source": [
    "We can now compare the speed of our three implementations. If you've implemented everything properly, the one-loop implementation should take less than 4 seconds to run, and the fully vectorized implementation should take less than 0.1 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "IN9cntDC5c5q",
    "outputId": "b78643e0-ce71-41b1-ffed-6f3e625ceafe"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timeit(f, *args):\n",
    "    tic = time.time()\n",
    "    f(*args) \n",
    "    toc = time.time()\n",
    "    return toc - tic\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train_rand = torch.randn(500, 3, 32, 32)\n",
    "x_test_rand = torch.randn(500, 3, 32, 32)\n",
    "\n",
    "two_loop_time = timeit(compute_distances_two_loops, x_train_rand, x_test_rand)\n",
    "print('Two loop version took %.2f seconds' % two_loop_time)\n",
    "\n",
    "one_loop_time = timeit(compute_distances_one_loop, x_train_rand, x_test_rand)\n",
    "speedup = two_loop_time / one_loop_time\n",
    "print('One loop version took %.2f seconds (%.1fX speedup)'\n",
    "      % (one_loop_time, speedup))\n",
    "\n",
    "no_loop_time = timeit(compute_distances_no_loops, x_train_rand, x_test_rand)\n",
    "speedup = two_loop_time / no_loop_time\n",
    "print('No loop version took %.2f seconds (%.1fX speedup)'\n",
    "      % (no_loop_time, speedup))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EudsSj5TrGGF"
   },
   "source": [
    "#### [Task] Predict labels\n",
    "Now that we have a method for computing distances between training and test examples, we need to implement a function that uses those distances together with the training labels to predict labels for test samples.\n",
    "\n",
    "Implement the function `predict_labels`. Before implementing the function, it is recommended to read the function description and NOTE inside the function. Moreover, you can only write your code in the predefined place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(dists, y_train, k=1):\n",
    "  \"\"\"\n",
    "  Given distances between all pairs of training and test samples, predict a\n",
    "  label for each test sample by taking a **majority vote** among its k nearest\n",
    "  neighbors in the training set.\n",
    "  In the event of a tie, this function **should** return the smallest label. For\n",
    "  example, if k=5 and the 5 nearest neighbors to a test example have labels\n",
    "  [1, 2, 1, 2, 3] then there is a tie between 1 and 2 (each have 2 votes), so\n",
    "  we should return 1 since it is the smallest label.\n",
    "s\n",
    "  This function should not modify any of its inputs.\n",
    "  Inputs:\n",
    "  - dists: Torch tensor of shape (num_train, num_test) where dists[i, j] is the\n",
    "    squared Euclidean distance between the ith training point and the jth test\n",
    "    point.\n",
    "  - y_train: Torch tensor of shape (num_train,) giving labels for all training\n",
    "    samples. Each label is an integer in the range [0, num_classes - 1]\n",
    "  - k: The number of nearest neighbors to use for classification.\n",
    "  Returns:\n",
    "  - y_pred: A torch int64 tensor of shape (num_test,) giving predicted labels\n",
    "    for the test data, where y_pred[j] is the predicted label for the jth test\n",
    "    example. Each label should be an integer in the range [0, num_classes - 1].\n",
    "  \"\"\"\n",
    "  num_train, num_test = dists.shape\n",
    "  y_pred = torch.zeros(num_test, dtype=torch.int64)\n",
    "  ##############################################################################\n",
    "  # TODO: Implement this function. You may use an explicit loop over the test  #\n",
    "  # samples. Hint: Look up the function torch.topk                             #\n",
    "  ##############################################################################\n",
    "  # Replace \"pass\" statement with your code\n",
    "  \n",
    "  pass\n",
    "  \n",
    "  ##############################################################################\n",
    "  #                             END OF YOUR CODE                               #\n",
    "  ##############################################################################\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MWk4BTMKfWz8",
    "outputId": "e4aa005a-ab93-4232-b27c-c1c365246f7d"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "dists = torch.tensor([\n",
    "    [0.3, 0.4, 0.1],\n",
    "    [0.1, 0.5, 0.5],\n",
    "    [0.4, 0.1, 0.2],\n",
    "    [0.2, 0.2, 0.4],\n",
    "    [0.5, 0.3, 0.3],\n",
    "])\n",
    "y_train_ = torch.tensor([0, 1, 0, 1, 2])\n",
    "y_pred_expected = torch.tensor([1, 0, 0])\n",
    "y_pred_ = predict_labels(dists, y_train_, k=3)\n",
    "correct_ = y_pred_.tolist() == y_pred_expected.tolist()\n",
    "print('Correct: ', correct_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMBf1Z6VF9hx"
   },
   "source": [
    "Now we have implemented all the required functionality for the K-Nearest Neighbor classifier. Complete the implementation of the `KnnClassifer` class. Before implementing the function, it is recommended to read the function description and NOTE inside the function. Moreover, you can only write your code in the predefined place. \n",
    "\n",
    "We can get some intuition into the KNN classifier by visualizing its predictions on toy 2D data. Here we will generate some random training and test points in 2D, and assign random labels to the training points. We can then make predictions for the test points, and visualize both training and test points. Training points are shown as stars, and tet points are shown as small transparent circles. The color of each point denots its label -- ground-truth label for training points, and predicted label for test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnClassifier:\n",
    "  def __init__(self, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Create a new K-Nearest Neighbor classifier with the specified training data.\n",
    "    In the initializer we simply memorize the provided training data.\n",
    "    Inputs:\n",
    "    - x_train: Torch tensor of shape (num_train, C, H, W) giving training data\n",
    "    - y_train: int64 torch tensor of shape (num_train,) giving training labels\n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the initializer for this class. It should perform no    #\n",
    "    # computation and simply memorize the training data.                      #\n",
    "    ###########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    pass\n",
    "    ###########################################################################\n",
    "    #                           END OF YOUR CODE                              #\n",
    "    ###########################################################################\n",
    "\n",
    "  def predict(self, x_test, k=1):\n",
    "    \"\"\"\n",
    "    Make predictions using the classifier.\n",
    "    Inputs:\n",
    "    - x_test: Torch tensor of shape (num_test, C, H, W) giving test samples\n",
    "    - k: The number of neighbors to use for predictions\n",
    "    Returns:\n",
    "    - y_test_pred: Torch tensor of shape (num_test,) giving predicted labels\n",
    "      for the test samples.\n",
    "    \"\"\"\n",
    "    y_test_pred = None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement this method. You should use the functions you wrote     #\n",
    "    # above for computing distances (use the no-loop variant) and to predict  #\n",
    "    # output labels.\n",
    "    ###########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    pass\n",
    "    ###########################################################################\n",
    "    #                           END OF YOUR CODE                              #\n",
    "    ###########################################################################\n",
    "    return y_test_pred\n",
    "\n",
    "  def check_accuracy(self, x_test, y_test, k=1, quiet=False):\n",
    "    \"\"\"\n",
    "    Utility method for checking the accuracy of this classifier on test data.\n",
    "    Returns the accuracy of the classifier on the test data, and also prints a\n",
    "    message giving the accuracy.\n",
    "    Inputs:\n",
    "    - x_test: Torch tensor of shape (num_test, C, H, W) giving test samples\n",
    "    - y_test: int64 torch tensor of shape (num_test,) giving test labels\n",
    "    - k: The number of neighbors to use for prediction\n",
    "    - quiet: If True, don't print a message.\n",
    "    Returns:\n",
    "    - accuracy: Accuracy of this classifier on the test data, as a percent.\n",
    "      Python float in the range [0, 100]\n",
    "    \"\"\"\n",
    "    y_test_pred = self.predict(x_test, k=k)\n",
    "    num_samples = x_test.shape[0]\n",
    "    num_correct = (y_test == y_test_pred).sum().item()\n",
    "    accuracy = 100.0 * num_correct / num_samples\n",
    "    msg = (f'Got {num_correct} / {num_samples} correct; '\n",
    "           f'accuracy is {accuracy:.2f}%')\n",
    "    if not quiet:\n",
    "      print(msg)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zTa7xowOfWz-",
    "outputId": "742be2a6-8d9c-47f2-8773-84f558b4f42d"
   },
   "outputs": [],
   "source": [
    "num_test = 10000\n",
    "num_train = 20\n",
    "num_classes = 5\n",
    "\n",
    "# Generate random training and test data\n",
    "torch.manual_seed(17)\n",
    "x_train_rand = torch.rand(num_train, 2)\n",
    "y_train_rand = torch.randint(num_classes, size=(num_train,))\n",
    "x_test_rand = torch.rand(num_test, 2)\n",
    "classifier = KnnClassifier(x_train_rand, y_train_rand)\n",
    "\n",
    "# Plot predictions for different values of k\n",
    "for k in [1, 3, 5]:\n",
    "    y_test_rand = classifier.predict(x_test_rand, k=k)\n",
    "    plt.gcf().set_size_inches(8, 8)\n",
    "    class_colors = ['r', 'g', 'b', 'k', 'y']\n",
    "    train_colors = [class_colors[c] for c in y_train_rand]\n",
    "    test_colors = [class_colors[c] for c in y_test_rand]\n",
    "    plt.scatter(x_test_rand[:, 0], x_test_rand[:, 1],\n",
    "                color=test_colors, marker='o', s=32, alpha=0.05)\n",
    "    plt.scatter(x_train_rand[:, 0], x_train_rand[:, 1],\n",
    "                color=train_colors, marker='*', s=128.0)\n",
    "    plt.title('Predictions for k = %d' % k, size=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tgNeDX0fW0A"
   },
   "source": [
    "We can use the exact same KNN code to perform image classification on CIFAR-10!\n",
    "\n",
    "Now lets put everything together and test our K-NN clasifier on a subset of CIFAR-10, using k=1:\n",
    "\n",
    "If you've implemented everything correctly you should see an accuracy of about 27%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "W5GVNBh0ySGN",
    "outputId": "32a4ed21-8d39-4c03-ed72-59a6e963da8e"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "num_train = 5000\n",
    "num_test = 500\n",
    "x_train, y_train, x_test, y_test = subsample_dataset(x_train_ori, y_train_ori, x_test_ori, y_test_ori, num_train, num_test)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "classifier.check_accuracy(x_test, y_test, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQwHpcPrIF5u"
   },
   "source": [
    "Now lets increase to k=5. You should see a slightly higher accuracy than k=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_a4zwcTe0PIK",
    "outputId": "f1d12b4a-8a70-4b8c-a6d4-8565036e57dd"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "num_train = 5000\n",
    "num_test = 500\n",
    "x_train, y_train, x_test, y_test = subsample_dataset(x_train_ori, y_train_ori, x_test_ori, y_test_ori, num_train, num_test)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "classifier.check_accuracy(x_test, y_test, k=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNyZLRmaIgT0"
   },
   "source": [
    "#### [Task] Cross-validation\n",
    "We have not implemented the full k-Nearest Neighbor classifier, but the choice of $k=5$ was arbitrary. We will use **cross-validation** to set this hyperparameter in a more principled manner.\n",
    "\n",
    "Implement the function `knn_cross_validate` to perform cross-validation on k. Before implementing the function, it is recommended to read the function description and NOTE inside the function. Moreover, you can only write your code in the predefined place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cross_validate(x_train, y_train, num_folds=5, k_choices=None):\n",
    "  \"\"\"\n",
    "  Perform cross-validation for KnnClassifier.\n",
    "  Inputs:\n",
    "  - x_train: Tensor of shape (num_train, C, H, W) giving all training data\n",
    "  - y_train: int64 tensor of shape (num_train,) giving labels for training data\n",
    "  - num_folds: Integer giving the number of folds to use\n",
    "  - k_choices: List of integers giving the values of k to try\n",
    "  Returns:\n",
    "  - k_to_accuracies: Dictionary mapping values of k to lists, where\n",
    "    k_to_accuracies[k][i] is the accuracy on the ith fold of a KnnClassifier\n",
    "    that uses k nearest neighbors.\n",
    "  \"\"\"\n",
    "  if k_choices is None:\n",
    "    # Use default values, do not change\n",
    "    k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "  # First we divide the training data into num_folds equally-sized folds.\n",
    "  x_train_folds = []\n",
    "  y_train_folds = []\n",
    "  ##############################################################################\n",
    "  # TODO: Split the training data and images into folds. After splitting,      #\n",
    "  # x_train_folds and y_train_folds should be lists of length num_folds, where #\n",
    "  # y_train_folds[i] is the label vector for images in x_train_folds[i].       #\n",
    "  # Hint: torch.chunk                                                          #\n",
    "  ##############################################################################\n",
    "  # Replace \"pass\" statement with your code\n",
    "  pass\n",
    "  ##############################################################################\n",
    "  #                            END OF YOUR CODE                                #\n",
    "  ##############################################################################\n",
    "\n",
    "  # A dictionary holding the accuracies for different values of k that we find\n",
    "  # when running cross-validation. After running cross-validation,\n",
    "  # k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "  # accuracies we found when trying KnnClassifiers that use k neighbors.\n",
    "  k_to_accuracies = {}\n",
    "\n",
    "  ##############################################################################\n",
    "  # TODO: Perform cross-validation to find the best value of k. For each value #\n",
    "  # of k in k_choices, run the k-nearest-neighbor algorithm num_folds times;   #\n",
    "  # in each case you'll use all but one fold as training data, and use the     #\n",
    "  # last fold as a validation set. Store the accuracies for all folds and all  #\n",
    "  # values in k in k_to_accuracies.   HINT: torch.cat                          #\n",
    "  ##############################################################################\n",
    "  # Replace \"pass\" statement with your code\n",
    "  pass\n",
    "  ##############################################################################\n",
    "  #                            END OF YOUR CODE                                #\n",
    "  ##############################################################################\n",
    "\n",
    "  return k_to_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "pA5MrumnLk5B",
    "outputId": "be8c8630-d020-4f79-f336-b76ce1f4bf6c"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "num_train = 5000\n",
    "num_test = 500\n",
    "x_train, y_train, x_test, y_test = subsample_dataset(x_train_ori, y_train_ori, x_test_ori, y_test_ori, num_train, num_test)\n",
    "\n",
    "k_to_accuracies = knn_cross_validate(x_train, y_train, num_folds=5)\n",
    "\n",
    "for k, accs in sorted(k_to_accuracies.items()):\n",
    "  print('k = %d got accuracies: %r' % (k, accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "id": "vMtPikIsNxl2",
    "outputId": "0443bc91-e5ec-4fb9-e430-62806604609e"
   },
   "outputs": [],
   "source": [
    "ks, means, stds = [], [], []\n",
    "torch.manual_seed(0)\n",
    "for k, accs in sorted(k_to_accuracies.items()):\n",
    "  plt.scatter([k] * len(accs), accs, color='r')\n",
    "  ks.append(k)\n",
    "  means.append(statistics.mean(accs))\n",
    "  stds.append(statistics.stdev(accs))\n",
    "plt.errorbar(ks, means, yerr=stds)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.title('Cross-validation on k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZ3Ue0bxmObU"
   },
   "source": [
    "Now we can use the results of cross-validation to select the best value for k, and rerun the classifier on our full 5000 set of training examples.\n",
    "\n",
    "You should get an accuracy above 28%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_get_best_k(k_to_accuracies):\n",
    "  best_k = 0\n",
    "  new_dict = {}\n",
    "  for k, accs in sorted(k_to_accuracies.items()):\n",
    "     new_dict[k] = sum(accs) / len(accs) \n",
    "  max_value = max(new_dict.values())\n",
    "  best_k = [k for k, v in new_dict.items() if v == max_value][0]\n",
    "  return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NBZfp1UtWyoG",
    "outputId": "b914f55f-070b-46b5-8bca-f84d7e82d88f"
   },
   "outputs": [],
   "source": [
    "best_k = 1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "best_k = knn_get_best_k(k_to_accuracies)    \n",
    "print('Best k is ', best_k)\n",
    "\n",
    "classifier = KnnClassifier(x_train, y_train)\n",
    "classifier.check_accuracy(x_test, y_test, k=best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1LevOE5mYJh"
   },
   "source": [
    "Finally, we can use our chosen value of k to run on the entire training and test sets.\n",
    "\n",
    "This may take a while to run, since the full training and test sets have 50k and 10k examples respectively. You should get an accuracy above 33%.\n",
    "\n",
    "**Run this only once!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5gcXjsjFkcGV",
    "outputId": "a5d21480-6f1d-456c-8b54-d56ba26f0550"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x_train_all, y_train_all, x_test_all, y_test_all = subsample_dataset(x_train_ori, y_train_ori, x_test_ori, y_test_ori)\n",
    "classifier = KnnClassifier(x_train_all, y_train_all)\n",
    "classifier.check_accuracy(x_test_all, y_test_all, k=best_k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for the k-NN questions, you can proceed to the next section!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hQrEwOpXb9Gh",
    "Cnf0BfHZfWzO",
    "SWSgBT8Wf3tW",
    "emQnvtnFeX1H",
    "GSd6jQb4epkC",
    "AKKdLGIIffYx",
    "-nLyYUhBgDKp",
    "NOZTkdiSmUFc",
    "aHkuvdr_1HqC",
    "EudsSj5TrGGF",
    "QNyZLRmaIgT0"
   ],
   "name": "knn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ccd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0aaa1cfb46689b04a922fee8d8ef5b92c689734100498de21197c2c4caffc1e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
