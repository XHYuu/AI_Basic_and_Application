{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIN7102 Applied Data Mining and Text Analytics: Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive Bayes implementation.\n",
    "code borrowed from: https://faculty.wcas.northwestern.edu/robvoigt/courses/2023_spring/ling334/assignments/a3.html\n",
    "\n",
    "API inspired by SciKit-learn.\n",
    "\"\"\"\n",
    "\n",
    "import os, math\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    \"\"\"Code for a bag-of-words Naive Bayes classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_dir='data/haiti/train', REMOVE_STOPWORDS=False):\n",
    "        self.REMOVE_STOPWORDS = REMOVE_STOPWORDS\n",
    "        self.stopwords = set([l.strip() for l in open('data/english.stop')])\n",
    "        self.classes = os.listdir(train_dir)\n",
    "        self.train_data = {c: os.path.join(train_dir, c) for c in self.classes}\n",
    "        self.vocabulary = set()\n",
    "        self.logprior = {}\n",
    "        self.loglikelihood = {}  # keys should be tuples in the form (w, c)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the Naive Bayes classification model, following the pseudocode for\n",
    "        training given in Figure 4.2 of SLP Chapter 4 (https://web.stanford.edu/~jurafsky/slp3/4.pdf).\n",
    "\n",
    "        Note that self.train_data contains the paths to training data files.\n",
    "        To get all the documents for a given training class c in a list, you can use:\n",
    "            c_docs = open(self.train_data[c]).readlines()\n",
    "\n",
    "        The dataset's are pre-tokenized so you can get words with\n",
    "        simply `words = doc.split()`\n",
    "\n",
    "        Remember to account for whether the self.REMOVE_STOPWORDS flag is set or not;\n",
    "        if it is True then the stopwords in self.stopwords should be removed whenever\n",
    "        they appear.\n",
    "\n",
    "        When converting from the pseudocode, consider how many loops over the data you\n",
    "        will need to properly estimate the parameters of the model, and what intermediary\n",
    "        variables you will need in this function to store the results of your computations.\n",
    "\n",
    "        Follow the TrainNaiveBayes pseudocode to update the relevant class variables:\n",
    "            - self.vocabulary, self.logprior, and self.loglikelihood.\n",
    "\n",
    "        Note that the keys for self.loglikelihood should be tuples in the form of (w, c)\n",
    "        where w is the string for the word and c is the string for the class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None (reads training data from self.train_data)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None (updates class attributes self.vocabulary, self.logprior, self.loglikelihood)\n",
    "        \"\"\"\n",
    "        # >>> YOUR ANSWER HERE\n",
    "        p_class = []\n",
    "        total_doc = 0\n",
    "        counters = []\n",
    "        total_word_in_class = []\n",
    "        for c in self.classes:\n",
    "            counter = Counter()\n",
    "            total_word = 0\n",
    "            c_docs = open(self.train_data[c]).readlines()\n",
    "            p_class.append(len(c_docs))\n",
    "            total_doc += len(c_docs)\n",
    "            for doc in c_docs:\n",
    "                words = re.split(r'[ \\n.,!?\":;()\\[\\]{}-]+', doc)\n",
    "                if self.REMOVE_STOPWORDS:\n",
    "                    words = [word.lower() for word in words\n",
    "                             if word.isalnum() and word.lower() not in self.stopwords]\n",
    "                else:\n",
    "                    words = [word.lower() for word in words]\n",
    "                for w in words:\n",
    "                    if w == \"\":\n",
    "                        continue\n",
    "                    counter[w] += 1\n",
    "                    total_word += 1\n",
    "                    self.vocabulary.add(w)\n",
    "            counters.append(counter)\n",
    "            total_word_in_class.append(total_word)\n",
    "\n",
    "        # Calculate class priors\n",
    "        for i, c in enumerate(self.classes):\n",
    "            self.logprior[c] = math.log(p_class[i] / total_doc)\n",
    "        # Calculate likelihoods\n",
    "        for i, counter in enumerate(counters):\n",
    "            for word, count in counter.items():\n",
    "                self.loglikelihood[(word, self.classes[i])] = \\\n",
    "                    math.log((count + 1.) / (total_word_in_class[i] + 1. * len(self.vocabulary)))\n",
    "\n",
    "        # >>> END YOUR ANSWER\n",
    "\n",
    "    def score(self, doc, c):\n",
    "        \"\"\"Return the log-probability of a given document for a given class,\n",
    "        using the trained Naive Bayes classifier.\n",
    "\n",
    "        This is analogous to the inside of the for loop in the TestNaiveBayes\n",
    "        pseudocode in Figure 4.2, SLP Chapter 4 (https://web.stanford.edu/~jurafsky/slp3/4.pdf).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc : str\n",
    "            The text of a document to score.\n",
    "        c : str\n",
    "            The name of the class to score it against.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The log-probability of the document under the model for class c.\n",
    "        \"\"\"\n",
    "        # >>> YOUR ANSWER HERE\n",
    "        words = re.split(r'[ \\n.,!?\":;()\\[\\]{}-]+', doc)\n",
    "        if self.REMOVE_STOPWORDS:\n",
    "            words = [word.lower() for word in words\n",
    "                     if word.isalnum() and word.lower() not in self.stopwords]\n",
    "        else:\n",
    "            words = [word.lower() for word in words]\n",
    "        log_p = self.logprior[c]\n",
    "        for word in words:\n",
    "            if word not in self.vocabulary or word == \"\" or (word, c) not in self.loglikelihood:\n",
    "                continue\n",
    "            log_p += self.loglikelihood[(word, c)]\n",
    "        return log_p\n",
    "        # >>> END YOUR ANSWER\n",
    "\n",
    "    def predict(self, doc):\n",
    "        \"\"\"Return the most likely class for a given document under the trained classifier model.\n",
    "        This should be only a few lines of code, and should make use of your self.score function.\n",
    "\n",
    "        Consider using the `max` built-in function. There are a number of ways to do this:\n",
    "           https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc : str\n",
    "            A text representation of a document to score.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The most likely class as predicted by the model.\n",
    "        \"\"\"\n",
    "        # >>> YOUR ANSWER HERE\n",
    "        max_score = -100000\n",
    "        pred = \"\"\n",
    "        for c in self.classes:\n",
    "            score = self.score(doc, c)\n",
    "            if max_score < score:\n",
    "                pred = c\n",
    "            else:\n",
    "                max_score = score\n",
    "        return pred\n",
    "        # >>> END YOUR ANSWER\n",
    "\n",
    "    def evaluate(self, test_dir='haiti/test', target='relevant'):\n",
    "        \"\"\"Calculate a precision, recall, and F1 score for the model\n",
    "        on a given test set.\n",
    "\n",
    "        Not the 'target' parameter here, giving the name of the class\n",
    "        to calculate relative to. So you can consider a True Positive\n",
    "        to be an instance where the gold label for the document is the\n",
    "        target and the model also predicts that label; a False Positive\n",
    "        to be an instance where the gold label is *not* the target, but\n",
    "        the model predicts that it is; and so on.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_dir : str\n",
    "            The path to a directory containing the test data.\n",
    "        target : str\n",
    "            The name of the class to calculate relative to.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (float, float, float)\n",
    "            The model's precision, recall, and F1 score relative to the\n",
    "            target class.\n",
    "        \"\"\"\n",
    "        test_data = {c: os.path.join(test_dir, c) for c in self.classes}\n",
    "        if not target in test_data:\n",
    "            print('Error: target class does not exist in test data.')\n",
    "            return\n",
    "        outcomes = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n",
    "        # >>> YOUR ANSWER HERE\n",
    "        # Calculate outcomes\n",
    "        for c in self.classes:\n",
    "            if c == target:\n",
    "                docs = open(test_data[c]).readlines()\n",
    "                for doc in docs:\n",
    "                    pred_c = self.predict(doc)\n",
    "                    if pred_c == c:\n",
    "                        outcomes['TP'] += 1\n",
    "                    else:\n",
    "                        outcomes['FN'] += 1\n",
    "            else:\n",
    "                docs = open(test_data[c]).readlines()\n",
    "                for doc in docs:\n",
    "                    pred_c = self.predict(doc)\n",
    "                    if pred_c == c:\n",
    "                        outcomes['TN'] += 1\n",
    "                    else:\n",
    "                        outcomes['FP'] += 1\n",
    "        # calculate precision, recall, and F1 score\n",
    "        precision = outcomes['TP'] / (outcomes['TP'] + outcomes['FP'])\n",
    "        recall = outcomes['TP'] / (outcomes['TP'] + outcomes['FN'])\n",
    "        f1_score = 2 * (precision * recall) / (recall + precision)\n",
    "        # >>> END YOUR ANSWER\n",
    "        return (precision, recall, f1_score)\n",
    "\n",
    "    def print_top_features(self, k=10):\n",
    "        results = {c: {} for c in self.classes}\n",
    "        for w in self.vocabulary:\n",
    "            for c in self.classes:\n",
    "                ratio = math.exp(self.loglikelihood[w, c] - min(\n",
    "                    self.loglikelihood[w, other_c] for other_c in self.classes if other_c != c))\n",
    "                results[c][w] = ratio\n",
    "\n",
    "        for c in self.classes:\n",
    "            print(f'Top features for class <{c.upper()}>')\n",
    "            for w, ratio in sorted(results[c].items(), key=lambda x: x[1], reverse=True)[0:k]:\n",
    "                print(f'\\t{w}\\t{ratio}')\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Evaluate your own Naive bayes models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on class <RELEVANT>, keeping stopwords\n",
      "\tPrecision: 0.6266666666666667\t Recall: 1.0\t F1: 0.7704918032786886\n",
      "\n",
      "Performance on class <RELEVANT>, removing stopwords\n",
      "\tPrecision: 0.6266666666666667\t Recall: 1.0\t F1: 0.7704918032786886\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('exipred', 'relevant')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/2233575104.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_top_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/3220711897.py\u001b[0m in \u001b[0;36mprint_top_features\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                 ratio = math.exp(self.loglikelihood[w, c] - min(\n\u001b[0m\u001b[0;32m    221\u001b[0m                     self.loglikelihood[w, other_c] for other_c in self.classes if other_c != c))\n\u001b[0;32m    222\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/3220711897.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 ratio = math.exp(self.loglikelihood[w, c] - min(\n\u001b[1;32m--> 221\u001b[1;33m                     self.loglikelihood[w, other_c] for other_c in self.classes if other_c != c))\n\u001b[0m\u001b[0;32m    222\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('exipred', 'relevant')"
     ]
    }
   ],
   "source": [
    "target = 'relevant'\n",
    "\n",
    "clf = NaiveBayesClassifier(train_dir = 'data/haiti/train')\n",
    "clf.train()\n",
    "print(f'Performance on class <{target.upper()}>, keeping stopwords')\n",
    "precision, recall, f1_score = clf.evaluate(test_dir = 'data/haiti/dev', target = target)\n",
    "print(f'\\tPrecision: {precision}\\t Recall: {recall}\\t F1: {f1_score}\\n')\n",
    "\n",
    "clf = NaiveBayesClassifier(train_dir = 'data/haiti/train', REMOVE_STOPWORDS=True)\n",
    "clf.train()\n",
    "print(f'Performance on class <{target.upper()}>, removing stopwords')\n",
    "precision, recall, f1_score = clf.evaluate(test_dir = 'data/haiti/dev', target = target)\n",
    "print(f'\\tPrecision: {precision}\\t Recall: {recall}\\t F1: {f1_score}\\n')\n",
    "\n",
    "\n",
    "clf.print_top_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
